# Server Development Environment Variables (for Docker)
# Copy this to server/.env.dev (DO NOT commit to git)
# This file is used by docker-compose.dev.yml

# ============================================
# Server Configuration
# ============================================
PORT=4000
NODE_ENV=development
DOMAIN=localhost
PROTOCOL=http

# ============================================
# Database
# Docker path: /app/prisma/dev.db
# ============================================
DATABASE_URL="file:/app/prisma/dev.db"

# ============================================
# JWT Authentication
# ============================================
ACCESS_TOKEN_SECRET=ACCESS_TOKEN_SECRET
REFRESH_TOKEN_SECRET=REFRESH_TOKEN_SECRET
ACCESS_TOKEN_EXPIRES_IN=1h
REFRESH_TOKEN_EXPIRES_IN=1d
GUEST_ACCESS_TOKEN_EXPIRES_IN=15m
GUEST_REFRESH_TOKEN_EXPIRES_IN=12h

# ============================================
# Initial Admin User
# ============================================
INITIAL_EMAIL_USER=user@llmui.com
INITIAL_PASSWORD_USER=123456

# ============================================
# File Uploads
# ============================================
UPLOAD_FOLDER=uploads

# ============================================
# Timezone
# ============================================
SERVER_TIMEZONE=Asia/Saigon

# ============================================
# Client URL (for CORS, redirects, etc.)
# ============================================
CLIENT_URL=http://localhost:3000

# ============================================
# Production Settings
# ============================================
PRODUCTION=false
DOCKER=true

# ============================================
# Production URL (not used in dev, but keep for compatibility)
# ============================================
PRODUCTION_URL=https://tuandev.ru

# ============================================
# LLM API Configuration
# ============================================
LLM_API_URL=http://llm.codex.so
LLM_API_TOKEN=user_pk_a2136a4efbfe36c54350469a496c9bee936a41a15d3ff37f
# LLM_API_MODEL=openai/gpt-5-mini

